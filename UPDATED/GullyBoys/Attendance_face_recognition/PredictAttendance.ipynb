{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import requests\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "curd = os.getcwd()\n",
    "try:  \n",
    "    os.mkdir(\"{}/known_people\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "try:  \n",
    "    os.mkdir(\"{}/models\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "try:  \n",
    "    os.mkdir(\"{}/test\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "try:  \n",
    "    os.mkdir(\"{}/unknown_pictures\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(frame, knn_clf=None, model_path=None, distance_threshold=0.5):\n",
    "    \n",
    "\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n",
    "\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    \n",
    "   # X_img = face_recognition.load_image_file(X_img_path)\n",
    "    X_img = frame\n",
    "    X_face_locations = face_recognition.face_locations(X_img)\n",
    "\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n",
    "\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my version\n",
    "def show_prediction_labels_on_image(frame, predictions):\n",
    "    \n",
    "    #pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    pil_image = Image.fromarray(frame).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "        \n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "    del draw\n",
    "\n",
    "    #pil_image.show()\n",
    "    #cv2.imshow(\"frame\",pil_image)\n",
    "    return np.asarray(pil_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceRecog on 10 stills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for faces in leos.jpg\n",
      "- Found LeoDiCap at (588, 291)\n",
      "- Found unknown at (959, 291)\n",
      "- Found unknown at (1478, 171)\n",
      "- Found unknown at (141, 350)\n",
      "Looking for faces in Y.jpg\n",
      "- Found LeoDiCap at (1526, 666)\n",
      "- Found unknown at (913, 82)\n",
      "- Found unknown at (855, 626)\n",
      "- Found unknown at (325, 641)\n",
      "- Found JasonMamoa at (253, 81)\n",
      "- Found unknown at (1491, 133)\n",
      "Looking for faces in eg.jpg\n",
      "- Found ElonMusk at (573, 106)\n",
      "- Found unknown at (872, 156)\n",
      "- Found unknown at (1031, 236)\n",
      "- Found unknown at (165, 86)\n",
      "- Found unknown at (404, 216)\n",
      "Looking for faces in elon.jpg\n",
      "- Found ElonMusk at (632, 204)\n",
      "- Found unknown at (134, 348)\n",
      "- Found unknown at (1382, 455)\n",
      "- Found unknown at (1097, 455)\n",
      "- Found unknown at (1419, 112)\n",
      "Looking for faces in Front-view-of-students-in-a-classroom-looking-forward-with-on-raising-his-hand.jpg\n",
      "- Found unknown at (633, 236)\n",
      "- Found unknown at (1210, 226)\n",
      "- Found unknown at (110, 325)\n",
      "- Found unknown at (901, 296)\n",
      "- Found unknown at (489, 489)\n",
      "- Found unknown at (1047, 345)\n",
      "- Found unknown at (1020, 191)\n",
      "Looking for faces in justiceleague.jpg\n",
      "- Found unknown at (228, 94)\n",
      "- Found unknown at (302, 78)\n",
      "- Found unknown at (151, 89)\n",
      "- Found unknown at (423, 61)\n",
      "- Found JasonMamoa at (45, 46)\n",
      "- Found unknown at (543, 39)\n"
     ]
    }
   ],
   "source": [
    "#Still Image Tester\n",
    "#curd = os.getcwd()\n",
    "for image_file in os.listdir(\"{}/test\".format(curd)):\n",
    "    full_file_path = os.path.join(\"{}/test\".format(curd), image_file)\n",
    "    if os.path.splitext(full_file_path)[1][1:] in ALLOWED_EXTENSIONS:\n",
    "\n",
    "        print(\"Looking for faces in {}\".format(image_file))\n",
    "        frame = cv2.imread(full_file_path,-1)\n",
    "\n",
    "        predictions = predict(frame, model_path=\"{}/models/trained_knn_model.clf\".format(curd))\n",
    "\n",
    "        for name, (top, right, bottom, left) in predictions:\n",
    "            print(\"- Found {} at ({}, {})\".format(name, left, top))\n",
    "            names.append(name)\n",
    "        # Display results overlaid on an image\n",
    "        #show_prediction_labels_on_image(frame, predictions)\n",
    "        final_img = show_prediction_labels_on_image(frame, predictions)\n",
    "        cv2.imshow(\"X\",final_img)\n",
    "        cv2.waitKey(0)    # Press enter every time to switch images and in the last image press q free kernel.\n",
    "    else:\n",
    "        continue\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Attendance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Count  Present\n",
      "LeoDiCap        2        1\n",
      "ElonMusk        2        1\n",
      "JasonMamoa      2        1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LeoDiCap</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElonMusk</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JasonMamoa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Present\n",
       "LeoDiCap          1\n",
       "ElonMusk          1\n",
       "JasonMamoa        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attendance System csv maker     \n",
    "namesD=pd.DataFrame(names, columns=[\"Names\"])\n",
    "namesD= namesD[namesD.Names!=\"unknown\"]\n",
    "\n",
    "attendance= pd.DataFrame(namesD.iloc[:,0].value_counts())\n",
    "attendance.rename(index=str,columns={'Names': 'Count'},inplace=True)\n",
    "attendance[\"Present\"] =0\n",
    "\n",
    "attendance[\"Count\"][0] >= 5 \n",
    "# This is so because we assume that in a class scanerio our web cam will take 10 photos in a span of a class period(50 min.)\n",
    "# And the people recognised in atleast 5 images will be marked present\n",
    "\n",
    "for i in range(attendance.shape[0]):\n",
    "    if(attendance[\"Count\"][i] > 1):\n",
    "        attendance[\"Present\"][i] =1\n",
    "\n",
    "print(attendance)\n",
    "print()\n",
    "attendance_final=attendance.drop(['Count'],axis=1)\n",
    "attendance_final\n",
    "#attendance_final.to_csv('Attendance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition on WebCam Video Stream(Surveillance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Found unknown at (637, 266)\n",
      "- Found unknown at (662, 242)\n",
      "- Found unknown at (655, 263)\n",
      "- Found unknown at (613, 242)\n",
      "- Found unknown at (613, 242)\n",
      "- Found unknown at (637, 217)\n",
      "- Found unknown at (675, 242)\n",
      "- Found JasonMamoa at (139, 426)\n",
      "- Found unknown at (662, 217)\n",
      "- Found JasonMamoa at (199, 438)\n",
      "- Found JasonMamoa at (199, 450)\n",
      "- Found unknown at (637, 242)\n",
      "- Found JasonMamoa at (187, 438)\n",
      "- Found unknown at (637, 242)\n",
      "- Found JasonMamoa at (199, 426)\n",
      "- Found unknown at (655, 242)\n",
      "- Found unknown at (353, 329)\n",
      "- Found unknown at (637, 242)\n",
      "- Found JasonMamoa at (432, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found unknown at (432, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (432, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (425, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (425, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (425, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (418, 350)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (418, 357)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (418, 357)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (405, 357)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (405, 357)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (405, 357)\n",
      "- Found unknown at (613, 242)\n",
      "- Found JasonMamoa at (405, 357)\n",
      "- Found unknown at (613, 242)\n",
      "- Found unknown at (613, 242)\n",
      "- Found unknown at (613, 242)\n",
      "- Found unknown at (588, 217)\n",
      "- Found unknown at (637, 217)\n",
      "- Found unknown at (613, 217)\n"
     ]
    }
   ],
   "source": [
    "#Live Video tester\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 100)\n",
    "rat, frame = cap.read()\n",
    "\n",
    "while(True):\n",
    "    rat, frame = cap.read()\n",
    "    predictions = predict(frame, model_path=\"{}/models/trained_knn_model.clf\".format(curd))\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        print(\"- Found {} at ({}, {})\".format(name, left, top))\n",
    "        names.append(name)\n",
    "\n",
    "        # Display results overlaid on an image\n",
    "    show_img = show_prediction_labels_on_image(frame, predictions)\n",
    "    cv2.imshow('img',show_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition on PhoneCam Video Stream(Surveillance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Live Video tester\n",
    "url = \"http://192.168.137.184:8080/shot.jpg\"\n",
    "\n",
    "while(True):\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content),dtype = np.uint8)\n",
    "    frame = cv2.imdecode(img_arr,-1)\n",
    "    predictions = predict(frame, model_path=\"{}/models/trained_knn_model.clf\".format(curd))\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        print(\"- Found {} at ({}, {})\".format(name, left, top))\n",
    "        names.append(name)\n",
    "\n",
    "        # Display results overlaid on an image\n",
    "    show_img = show_prediction_labels_on_image(frame, predictions)\n",
    "    cv2.imshow('img',show_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
